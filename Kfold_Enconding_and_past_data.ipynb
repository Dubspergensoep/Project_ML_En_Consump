{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kfold encoding and past data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we combine the result from 'more_past_data.ipynb' and 'KFold_Encoding.ipynb'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup\n",
    "df = pd.read_csv(\"consumption.csv\")\n",
    "weather_avg = pd.read_csv('weather-avg.csv')\n",
    "weather_min = pd.read_csv('weather-min.csv')\n",
    "weather_max = pd.read_csv('weather-max.csv')\n",
    "info = pd.read_csv('addinfo.csv')\n",
    "weather_avg = weather_avg.set_index(\"meter_id\")\n",
    "weather_min = weather_min.set_index(\"meter_id\")\n",
    "weather_max = weather_max.set_index(\"meter_id\")\n",
    "info = info.set_index(\"meter_id\")\n",
    "weather_avg_sorted = weather_avg.reindex(df.iloc[:,0])\n",
    "weather_min_sorted = weather_min.reindex(df.iloc[:,0])\n",
    "weather_max_sorted = weather_max.reindex(df.iloc[:,0])\n",
    "info_sorted = info.reindex(df.iloc[:,0])\n",
    "brinfo=info_sorted['num_bedrooms']\n",
    "values = {'num_bedrooms' : brinfo.mean()}\n",
    "info_filled_br = info_sorted.fillna(value = values)\n",
    "brinfo_filled = info_filled_br['num_bedrooms']\n",
    "#functions\n",
    "def get_monthi(n):\n",
    "    begin=48*31*(n-1)+1\n",
    "    end=48*31*n\n",
    "    if n==1:\n",
    "        begin=1\n",
    "    if n>1:\n",
    "        end-=3*48\n",
    "    if n>2:\n",
    "        begin-=3*48\n",
    "    if n>3:\n",
    "        end-=48\n",
    "    if n>4:\n",
    "        begin-=48\n",
    "    if n>5:\n",
    "        end-=48\n",
    "    if n>6:\n",
    "        begin-=48\n",
    "    if n>8:\n",
    "        end-=48\n",
    "    if n>9:\n",
    "        begin-=48\n",
    "    if n>10:\n",
    "        end-=48\n",
    "    if n>11:\n",
    "        begin-=48\n",
    "    return begin,end\n",
    "\n",
    "def get_mean_temp(row,month):\n",
    "    \"\"\"\n",
    "    row: is the row (meter_id) we would like to get the average temperature for.\n",
    "    month: which month (columns) we would get the average temperature for.\n",
    "    returns: the average temperature for a specific meter_id for a specific month.\n",
    "    \"\"\"\n",
    "    if month==1:\n",
    "        return row.loc[:,\"2017-01-01 00:00:00\":\"2017-01-31 00:00:00\"].mean(1)\n",
    "    elif month==2:\n",
    "        return row.loc[:,\"2017-02-01 00:00:00\":\"2017-02-28 00:00:00\"].mean(1)\n",
    "    elif month==3:\n",
    "        return row.loc[:,\"2017-03-01 00:00:00\":\"2017-03-31 00:00:00\"].mean(1)\n",
    "    elif month==4:\n",
    "        return row.loc[:,\"2017-04-01 00:00:00\":\"2017-04-30 00:00:00\"].mean(1)\n",
    "    elif month==5:\n",
    "        return row.loc[:,\"2017-05-01 00:00:00\":\"2017-05-31 00:00:00\"].mean(1)\n",
    "    elif month==6:\n",
    "        return row.loc[:,\"2017-06-01 00:00:00\":\"2017-06-30 00:00:00\"].mean(1)\n",
    "    elif month==7:\n",
    "        return row.loc[:,\"2017-07-01 00:00:00\":\"2017-07-31 00:00:00\"].mean(1)\n",
    "    elif month==8:\n",
    "        return row.loc[:,\"2017-08-01 00:00:00\":\"2017-08-31 00:00:00\"].mean(1)\n",
    "    elif month==9:\n",
    "        return row.loc[:,\"2017-09-01 00:00:00\":\"2017-09-30 00:00:00\"].mean(1)\n",
    "    elif month==10:\n",
    "        return row.loc[:,\"2017-10-01 00:00:00\":\"2017-10-31 00:00:00\"].mean(1)\n",
    "    elif month==11:\n",
    "        return row.loc[:,\"2017-11-01 00:00:00\":\"2017-11-30 00:00:00\"].mean(1)\n",
    "    elif month==12:\n",
    "        return row.loc[:,\"2017-12-01 00:00:00\":\"2017-12-31 00:00:00\"].mean(1)\n",
    "    else:\n",
    "        print(\"Error: this is not a valid input for month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meter_id\n",
       "0xa62b9f23553ff183f61e2bf943aab3d5983d02d7    2.0\n",
       "0x459c834d1f6cfb5b734b82aa9f5410fa97fb70da   -1.0\n",
       "0x4a1ed36825360a058cec2bdd409fc2459e1ce54f   -1.0\n",
       "0x5b76d3c0e0aefc6e0a8d1d031f96388a23263407   -1.0\n",
       "0x943ebe39ef2be6ef807c42c5a647e27112ca5b0f   -1.0\n",
       "                                             ... \n",
       "0x7dd7a7b8ee1bec7c44b24f738c752482f6161065   -1.0\n",
       "0xfdaf9f857621ec06f2cf801f42a020a322835090   -1.0\n",
       "0xd28f2f001e0cd4d6c121a3cb2e1427207e170e18   -1.0\n",
       "0x47218b46abb2fcaade487a211911406dc6e13730   -1.0\n",
       "0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd   -1.0\n",
       "Name: num_bedrooms, Length: 3248, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Filling missing values with a value outside the range i.e. -1 as a dummy variable:\n",
    "# Filling the mean value for the NaN values in num_bedrooms column:\n",
    "values = {'num_bedrooms' : -1}\n",
    "info_filled_br_dummy = info_sorted.fillna(value = values)\n",
    "brinfo_filled_dummy = info_filled_br_dummy['num_bedrooms']\n",
    "brinfo_filled_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new function to load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_data(nim):\n",
    "    NaN_t=1200\n",
    "    En_con=[]\n",
    "    #number of input months (if nim=1 we should get the same as before)\n",
    "    #this is the amount of months we want in our input space to predict the next monthly consumption     \n",
    "    prev_con=[] #previous consumtion\n",
    "    #extra info\n",
    "    temps=[]\n",
    "    temps_min=[]\n",
    "    temps_max=[]\n",
    "    month_arr=[]\n",
    "    br_arr=[]\n",
    "    br_arr_dummy=[]\n",
    "    dwelling_type_bungalow=[]\n",
    "    dwelling_type_detached_house=[]\n",
    "    dwelling_type_flat=[]\n",
    "    dwelling_type_semi_detached_house=[]\n",
    "    dwelling_type_terraced_house=[]\n",
    "    y = pd.get_dummies(info_sorted.dwelling_type, prefix='dwelling_type')\n",
    "    \n",
    "    \n",
    "    for i in range(df.shape[0]): # loop over all users\n",
    "        meter=df.iloc[i] # = row number i  \n",
    "    \n",
    "        #loop over all month from januari until month 12-nim\n",
    "        #if the month is higher then this we don't have enough data for the nim input variables and the 1 output variable\n",
    "        for m in range (1,13-nim): \n",
    "            #load current month\n",
    "            bi, ei =get_monthi(m)               #bi (begin index) ei(end index)\n",
    "            month=meter[bi:ei]  #data for the month m for the row user (row) i\n",
    "            #load bedroom info\n",
    "            row = brinfo_filled[i:i+1]\n",
    "            row_dummy = brinfo_filled_dummy[i:i+1]\n",
    "            #Load dwelling type\n",
    "            dew_type_row = y[i:i+1]\n",
    "            \n",
    "            # Count the amount of NaN's in current      \n",
    "            n_NaN=month.isnull().sum() \n",
    "\n",
    "            # Check if months have numeric values otherwise discard the month for this user. \n",
    "            if n_NaN<NaN_t:\n",
    "                for j in range(m,13-nim):\n",
    "                    #save input for month j,j+1,..,j+nim-1\n",
    "                    input_months=np.zeros(nim)\n",
    "                    for k in range(nim):\n",
    "                        #load month for input j+k\n",
    "                        bik,eik=get_monthi(j+k)\n",
    "                        input_months[k]=meter[bik:eik].mean()\n",
    "                    #debug if statement checks for NaN in input month\n",
    "                    if np.isnan(np.sum(input_months)):\n",
    "                        print(\"months=%i index=%i\" %(j,i))\n",
    "                        print(input_months)\n",
    "                    prev_con.append(input_months)\n",
    "                    #save output for month j+nim\n",
    "                    bio,eio=get_monthi(j+nim)\n",
    "                    En_con.append(meter[bio:eio].mean())\n",
    "                    #save extra information \n",
    "                    temps.append(get_mean_temp(weather_avg_sorted.iloc[i:i+1],j+nim))\n",
    "                    temps_min.append(get_mean_temp(weather_min_sorted.iloc[i:i+1],j+nim))\n",
    "                    temps_max.append(get_mean_temp(weather_max_sorted.iloc[i:i+1],j+nim))\n",
    "                    month_arr.append(j+nim)\n",
    "                    br_arr.append(row[0])\n",
    "                    br_arr_dummy.append(row_dummy[0])\n",
    "                    dwelling_type_bungalow.append(dew_type_row.iloc[0, 0])\n",
    "                    dwelling_type_detached_house.append(dew_type_row.iloc[0, 1])\n",
    "                    dwelling_type_flat.append(dew_type_row.iloc[0, 2])\n",
    "                    dwelling_type_semi_detached_house.append(dew_type_row.iloc[0, 3])\n",
    "                    dwelling_type_terraced_house.append(dew_type_row.iloc[0, 4])\n",
    "\n",
    "                    \n",
    "                \n",
    "                \n",
    "                #break out of outer month loops since the inner month loop takes care of all months\n",
    "                break\n",
    "    # converting list to numpy arrays: \n",
    "    nptemps = np.zeros(len(temps))\n",
    "    nptemps_min = np.zeros(len(temps_min))\n",
    "    nptemps_max = np.zeros(len(temps_max))\n",
    "    npEn_con = np.zeros(len(En_con))\n",
    "    npmonth_arr = np.zeros(len(month_arr))\n",
    "    npbr_arr = np.zeros(len(br_arr)) #converting it into numpy array.\n",
    "    npbr_arr_dummy = np.zeros(len(br_arr_dummy)) #converting it into numpy array.\n",
    "\n",
    "    for i in range(len(temps)):\n",
    "         nptemps[i] = temps[i]\n",
    "\n",
    "    for i in range(len(temps_min)):\n",
    "         nptemps_min[i] = temps_min[i]\n",
    "\n",
    "    for i in range(len(temps_max)):\n",
    "         nptemps_max[i] = temps_max[i]\n",
    "\n",
    "    for i in range(len(En_con)):\n",
    "         npEn_con[i] = En_con[i]\n",
    "\n",
    "    for i in range(len(month_arr)):\n",
    "         npmonth_arr[i] = month_arr[i]\n",
    "\n",
    "    for i in range(len(br_arr)):\n",
    "        npbr_arr[i] = br_arr[i]        \n",
    "    \n",
    "    for i in range(len(br_arr_dummy)):\n",
    "        npbr_arr_dummy[i] = br_arr_dummy[i]\n",
    "        \n",
    "    npprev_con=np.array(prev_con)\n",
    "    dw_t_b = np.array(dwelling_type_bungalow)\n",
    "    dw_t_d = np.array(dwelling_type_detached_house)\n",
    "    dw_t_f = np.array(dwelling_type_flat)\n",
    "    dw_t_s = np.array(dwelling_type_semi_detached_house)\n",
    "    dw_t_t = np.array(dwelling_type_terraced_house)\n",
    "    \n",
    "    #This should probably be done differently \n",
    "    return npEn_con,npprev_con,nptemps,nptemps_min,nptemps_max,npmonth_arr,npbr_arr,npbr_arr_dummy,dw_t_b,dw_t_d,dw_t_f,dw_t_s,dw_t_t\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nim=1\n",
    "npEn_con1,npprev_con1,nptemps1,nptemps_min1,nptemps_max1,npmonth_arr1,npbr_arr1,npbr_arr_dummy1,dw_t_b1,dw_t_d1,dw_t_f1,dw_t_s1,dw_t_t1=sort_data(1)\n",
    "#nim=2\n",
    "npEn_con2,npprev_con2,nptemps2,nptemps_min2,nptemps_max2,npmonth_arr2,npbr_arr2,npbr_arr_dummy2,dw_t_b2,dw_t_d2,dw_t_f2,dw_t_s2,dw_t_t2=sort_data(2)\n",
    "#nim=3\n",
    "npEn_con3,npprev_con3,nptemps3,nptemps_min3,nptemps_max3,npmonth_arr3,npbr_arr3,npbr_arr_dummy3,dw_t_b3,dw_t_d3,dw_t_f3,dw_t_s3,dw_t_t3=sort_data(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReÃ«valutate previous setups from more_past_data with Kfold encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the test from the notebook more_past_data will be recreate to measure the error with the Kfold crossvalidatation and random splits. Later on the extra variable like dwelling type will also be added\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eval_random_Split(features,npEn_con,split,model,print_res=True):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features , npEn_con.reshape(-1,1), test_size=split, random_state=0)\n",
    "    #print(X_train.shape, y_train.shape)\n",
    "    #print(X_test.shape, y_test.shape)\n",
    "    model.fit(X_train,y_train)\n",
    "    if print_res:\n",
    "        y_pred=model.predict(X_test)\n",
    "        print('Coefficients: \\n', model.coef_)\n",
    "        print('Intercept: {}'.format(model.intercept_))\n",
    "        # The mean squared error\n",
    "        print('Mean squared error: %.8f' % mean_squared_error(y_test, y_pred))\n",
    "        # The coefficient of determination: 1 is perfect prediction\n",
    "        print('Coefficient of determination: %.8f' % r2_score(y_test, y_pred))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[1.01008592]]\n",
      "Intercept: [0.00831724]\n",
      "Mean squared error: 0.00323402\n",
      "Coefficient of determination: 0.83505367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 month of previous data\n",
    "Eval_random_Split(npprev_con1,npEn_con1,0.3,LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R2 and MSE value is better then before(0.8186 and 0.00381149) this could be dought to the better randomized training or the easier test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 months\n",
      "Coefficients: \n",
      " [[-0.32214394  1.31486463]]\n",
      "Intercept: [0.01136229]\n",
      "Mean squared error: 0.00282637\n",
      "Coefficient of determination: 0.85470846\n",
      "3 months\n",
      "Coefficients: \n",
      " [[-0.16042959 -0.06958152  1.23612595]]\n",
      "Intercept: [0.01144688]\n",
      "Mean squared error: 0.00330198\n",
      "Coefficient of determination: 0.83436158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"2 months\")\n",
    "Eval_random_Split(npprev_con2,npEn_con2,0.3,LinearRegression())\n",
    "print(\"3 months\")\n",
    "Eval_random_Split(npprev_con3,npEn_con3,0.3,LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 months result in a similar story to the 1 month case.<br>\n",
    "For 3 months there is a decrease in the accuracy. I have no explenation for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_1D(features,npEn_con,split,model,print_res=True):\n",
    "    #extract only the last month from the features\n",
    "    features_lm=features[:,(features.shape[-1]-1)]\n",
    "    features_lm=features_lm.reshape(-1,1)\n",
    "    #use previously made function\n",
    "    return Eval_random_Split(features_lm,npEn_con,split,model,print_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 months 1D check\n",
      "Coefficients: \n",
      " [[1.04247136]]\n",
      "Intercept: [0.00448163]\n",
      "Mean squared error: 0.00297290\n",
      "Coefficient of determination: 0.84717579\n",
      "\n",
      "3 months 1D check\n",
      "Coefficients: \n",
      " [[1.05911266]]\n",
      "Intercept: [0.00383822]\n",
      "Mean squared error: 0.00353348\n",
      "Coefficient of determination: 0.82274906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"2 months 1D check\")\n",
    "Check_1D(npprev_con2,npEn_con2,0.3,LinearRegression())\n",
    "print(\"\\n3 months 1D check\")\n",
    "Check_1D(npprev_con3,npEn_con3,0.3,LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like most of the improvements are due to the smaller data set but there is a small improvment due to the extra information. Because the result for 3 months is very poor incomparison to the \"more past data\" notebook, we'll only repeat the test for 2 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nim=2\n",
    "#np_features= np.zeros(shape = (len(nptemps2), nim+4))\n",
    "\n",
    "#for i in range(len(nptemps2)):\n",
    "#    np_features[i, 0:nim]  = npprev_con2[i,:]\n",
    "#    np_features[i, nim] = nptemps2[i]\n",
    "#    np_features[i, nim+1] = nptemps_min2[i]\n",
    "#    np_features[i, nim+2] = nptemps_max2[i]\n",
    "#    np_features[i, nim+3] = npbr_arr2[i]\n",
    "\n",
    "#This does the above in 1 line\n",
    "np_features=np.column_stack(((npprev_con2,nptemps2,nptemps_min2, nptemps_max2, npbr_arr2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[-0.26161656  1.24849317  0.0034595   0.00189202 -0.00656957  0.00287161]]\n",
      "Intercept: [0.04612932]\n",
      "Mean squared error: 0.00271353\n",
      "Coefficient of determination: 0.86050883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eval_random_Split(np_features,npEn_con2,0.3,LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slight improvement after adding the extra features. Slightly worse then non random result but this might depend on the seed. <br>\n",
    "We'll now use normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z-normalization on data:\n",
    "def normalise_features(np_features):\n",
    "    #np_features_norm= np.zeros(shape = np_features.shape)\n",
    "    np_features_norm=np_features\n",
    "    if np_features.ndim==1:\n",
    "        np_features_norm=(np_features-np.mean(np_features))/np.std(np_features)\n",
    "    else: \n",
    "        for i in range(np_features.shape[1]):\n",
    "            np_features_norm[:,i] = (np_features[:,i]-np.mean(np_features[:,i]))/np.std(np_features[:,i])\n",
    "    return np_features_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[-0.2166253   1.09890608  0.10741244  0.05241113 -0.23258458  0.0109377 ]]\n",
      "Intercept: [-0.00156118]\n",
      "Mean squared error: 0.13526234\n",
      "Coefficient of determination: 0.86050883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_features_norm=normalise_features(np_features)\n",
    "npEn_con2_norm=normalise_features(npEn_con2) #perhaps normalise_features is not the best name\n",
    "Eval_random_Split(np_features_norm,npEn_con2_norm,0.3,LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE changes but R2 is the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now add dwelling type information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_features=np.column_stack(((npprev_con2,nptemps2,nptemps_min2, nptemps_max2, npbr_arr2,dw_t_b2,dw_t_d2,dw_t_f2,dw_t_s2,dw_t_t2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[-2.61096489e-01  1.24861183e+00  3.13197473e-03  1.98467949e-03\n",
      "  -6.35750080e-03  3.06418248e-03 -4.63528659e-04 -2.63050358e-03\n",
      "  -2.01450897e-03 -3.27842103e-03 -9.65673950e-04]]\n",
      "Intercept: [0.04642805]\n",
      "Mean squared error: 0.00271466\n",
      "Coefficient of determination: 0.86045083\n",
      "\n",
      " Normalised\n",
      "Coefficients: \n",
      " [[-2.16194670e-01  1.09901053e+00  9.72431387e-02  5.49779826e-02\n",
      "  -2.25076576e-01  1.16712138e-02 -9.42181784e-04 -5.82424552e-03\n",
      "  -2.08285255e-03 -9.41635362e-03 -2.04366111e-03]]\n",
      "Intercept: [-0.00161761]\n",
      "Mean squared error: 0.13531858\n",
      "Coefficient of determination: 0.86045083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eval_random_Split(np_features,npEn_con2,0.3,LinearRegression())\n",
    "print(\"\\n Normalised\")\n",
    "np_features_norm=normalise_features(np_features)\n",
    "npEn_con2_norm=normalise_features(npEn_con2) #perhaps normalise_features is not the best name\n",
    "Eval_random_Split(np_features_norm,npEn_con2_norm,0.3,LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are slightly worse with the extra infomation. strange <br>\n",
    "The coefficients of these components are alsmost zero(1e-3)so maybe addition of these components resulted in extra noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K fold crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eval_Kfold_Split(features,npEn_con,n_splits,model,print_res=True):\n",
    "    kf = KFold(n_splits, shuffle=True)\n",
    "    models_arr=[]\n",
    "    MSE_arr=[]\n",
    "    R2_arr=[]\n",
    "    for train_index, test_index in kf.split(features): \n",
    "        cmodel=model\n",
    "        cmodel.fit(features[train_index,],npEn_con[train_index])\n",
    "        models_arr.append(cmodel)\n",
    "        y_pred = model.predict(features[test_index,])\n",
    "        MSE_arr.append(mean_squared_error(npEn_con[test_index,], y_pred));\n",
    "        R2_arr.append(r2_score(npEn_con[test_index,], y_pred))\n",
    "    if print_res:\n",
    "        # The mean squared error\n",
    "        print('Mean squared error:')\n",
    "        print(np.mean(MSE_arr))\n",
    "        # The coefficient of determination: 1 is perfect prediction\n",
    "        print('Coefficient of determination: ' )\n",
    "        print(np.mean(R2_arr))\n",
    "    return models_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 months\n",
      "Mean squared error:\n",
      "0.003137588527636117\n",
      "Coefficient of determination: \n",
      "0.8442307822092066\n",
      "\n",
      "\n",
      "2 months\n",
      "Mean squared error:\n",
      "0.0029432519127855924\n",
      "Coefficient of determination: \n",
      "0.8520938825111755\n",
      "3 months\n",
      "Mean squared error:\n",
      "0.002989671454428639\n",
      "Coefficient of determination: \n",
      "0.852745625807929\n"
     ]
    }
   ],
   "source": [
    "#1 month\n",
    "print(\"1 months\")\n",
    "np_features=np.column_stack(((npprev_con1,nptemps1,nptemps_min1, nptemps_max1, npbr_arr1)))\n",
    "models_arr=Eval_Kfold_Split(np_features,npEn_con1,10,LinearRegression())\n",
    "print(\"\\n\")\n",
    "#2 months\n",
    "print(\"2 months\")\n",
    "np_features=np.column_stack(((npprev_con2,nptemps2,nptemps_min2, nptemps_max2, npbr_arr2)))\n",
    "models_arr=Eval_Kfold_Split(np_features,npEn_con2,10,LinearRegression())\n",
    "#2 months\n",
    "print(\"\\n 3 months\")\n",
    "np_features=np.column_stack(((npprev_con3,nptemps3,nptemps_min3, nptemps_max3, npbr_arr3)))\n",
    "models_arr=Eval_Kfold_Split(np_features,npEn_con3,10,LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 months\n",
      "Mean squared error:\n",
      "0.15580694251186425\n",
      "Coefficient of determination: \n",
      "0.8440378834414213\n",
      "\n",
      "\n",
      "2 months\n",
      "Mean squared error:\n",
      "0.14661010890770895\n",
      "Coefficient of determination: \n",
      "0.8529708901177872\n"
     ]
    }
   ],
   "source": [
    "#the same but normalised\n",
    "print(\"1 months\")\n",
    "np_features=np.column_stack(((npprev_con1,nptemps1,nptemps_min1, nptemps_max1, npbr_arr1)))\n",
    "np_features_norm=normalise_features(np_features)\n",
    "npEn_con1_norm=normalise_features(npEn_con1)\n",
    "models_arr=Eval_Kfold_Split(np_features_norm,npEn_con1_norm,10,LinearRegression())\n",
    "print(\"\\n\")\n",
    "print(\"2 months\")\n",
    "np_features=np.column_stack(((npprev_con2,nptemps2,nptemps_min2, nptemps_max2, npbr_arr2)))\n",
    "np_features_norm=normalise_features(np_features)\n",
    "npEn_con2_norm=normalise_features(npEn_con2)\n",
    "models_arr=Eval_Kfold_Split(np_features_norm,npEn_con2_norm,10,LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 months\n",
      "Mean squared error:\n",
      "0.003137344698948375\n",
      "Coefficient of determination: \n",
      "0.8445424751389631\n",
      "normalised\n",
      "Mean squared error:\n",
      "0.15577994596890393\n",
      "Coefficient of determination: \n",
      "0.8443358607467972\n",
      "\n",
      "\n",
      "2 months\n",
      "Mean squared error:\n",
      "0.0029432062113013977\n",
      "Coefficient of determination: \n",
      "0.8526624010669828\n",
      "normalised\n",
      "Mean squared error:\n",
      "0.14673926913578075\n",
      "Coefficient of determination: \n",
      "0.8539250214343251\n"
     ]
    }
   ],
   "source": [
    "#extra features\n",
    "np_features=np.column_stack(((npprev_con1,nptemps1,nptemps_min1, nptemps_max1, npbr_arr1,dw_t_b1,dw_t_d1,dw_t_f1,dw_t_s1,dw_t_t1)))\n",
    "print(\"1 months\")\n",
    "np_features=np.column_stack(((npprev_con1,nptemps1,nptemps_min1, nptemps_max1, npbr_arr1)))\n",
    "models_arr=Eval_Kfold_Split(np_features,npEn_con1,10,LinearRegression())\n",
    "print(\"normalised\")\n",
    "np_features_norm=normalise_features(np_features)\n",
    "npEn_con1_norm=normalise_features(npEn_con1)\n",
    "models_arr=Eval_Kfold_Split(np_features_norm,npEn_con1_norm,10,LinearRegression())\n",
    "print(\"\\n\")\n",
    "print(\"2 months\")\n",
    "np_features=np.column_stack(((npprev_con2,nptemps2,nptemps_min2, nptemps_max2, npbr_arr2,dw_t_b2,dw_t_d2,dw_t_f2,dw_t_s2,dw_t_t2)))\n",
    "models_arr=Eval_Kfold_Split(np_features,npEn_con2,10,LinearRegression())\n",
    "print(\"normalised\")\n",
    "np_features_norm=normalise_features(np_features)\n",
    "npEn_con2_norm=normalise_features(npEn_con2)\n",
    "models_arr=Eval_Kfold_Split(np_features_norm,npEn_con2_norm,10,LinearRegression())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
